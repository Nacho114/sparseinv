%%% document layout
\documentclass[paper=A4, fontsize=11pt]{scrartcl}
\setlength\parindent{0pt}
\usepackage[margin=1in]{geometry}

%%% packages
\usepackage{amsmath,amssymb,amsthm}
\usepackage{bbm}
\usepackage{complexity}
\usepackage{tcolorbox}
\usepackage{mathrsfs}

\usepackage{amsthm}


%%% hacks
\setlength\parindent{0pt}
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}
\let\originalleft\left
\let\originalright\right
\renewcommand{\left}{\mathopen{}\mathclose\bgroup\originalleft}
\renewcommand{\right}{\aftergroup\egroup\originalright}

%%% macros
\let\oldpr\Pr
\renewcommand{\Pr}[1]{\oldpr\left( #1 \right)}
\newcommand{\Prsub}[2]{\oldpr_{#1}\left( #2 \right)}
\newcommand{\EX}[1]{{{\mathbb{E}}\left[#1\right]}}
\newcommand{\EXSUB}[2]{{{\mathbb{E}}_{#1}\left[#2\right]}}
\newcommand{\VAR}[1]{\text{Var}\left[#1\right]}
\newcommand{\COVAR}[2]{\text{Cov}\left[#1,\, #2\right]}
\newcommand{\ZO}{\{0, \, 1\}}
\newcommand{\median}[1]{\text{med}\left\lbrace #1\right\rbrace}
\newcommand{\order}[1]{\mathcal{O}\left(#1\right)}
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\indicator}[1]{\mathbf{1}_{\left[#1\right]}}
\newcommand{\twosum}[2]{\sum_{\substack{#1\\#2}}}
\newcommand{\support}[1]{\textup{sup}\left(#1\right)}
\newcommand{\partspace}{\vspace{.3cm}}
\newcommand{\exspace}{\vspace{.8cm}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

%%% envs def
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}

%\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
%\newtheorem{lemma}[theorem]{Lemma}


\newcommand{\dk}{g_{kk}} % D_kk
\newcommand{\dktil}{\tilde{g}_{kk}} % Dtil_kk


%%% title
\title{Sparse Approximate Inverse Preconditioner}
\subtitle{Computational Linear Algebra}
\author{Sidak Pal Singh}

\begin{document}
	\maketitle
	%\textbf{Disclaimer: } This project follows closely a project given in a different class covering convex optimization.
	
	\section{Abstract}
	
	In this project, the aim is to construct a sparse preconditioner M for a given sparse matrix A. More specifially, we look for a right preconditioner M such that $\|I-A M\|_{F}$ is minimized. \\
	One of the most successful general-purpose methods for achiev- ing this tasks is SPAI by Grote and Huckle [3]. Improvements to the method from [3] have been described in [2]. The paper [1] provides an overview of these and similar methods.
	
	
	\section{Introduction}
	
	intro of sparse inverse problem
	
	\newpage
	
	\section{SPAI}
	
	Goal
	
	\begin{equation}
	\|A M-I\|_{F}^{2}=\sum_{k=1}^{n}\left\|(A M-I) e_{k}\right\|_{2}^{2}
	\end{equation}
	
	i.e. n independent least squares
	
	
	\begin{equation}
	\min _{m_{k}}\left\|A m_{k}-e_{k}\right\|_{2}, \quad k=1, \ldots, n
	\end{equation}
	
	
	How to compute sparsity structure 
	
	Now let \(\mathcal{J}\) be the set of indices \(j\) such that \(m_{k}(j) \neq 0\) We denote the reduced vector of unknowns \(m_{k}(\mathcal{J})\) by \(\hat{m}_{k} .\) Next, let \(\mathcal{I}\) be the set of
	indices \(i\) such that \(A(i, \mathcal{J})\) is not identically zero. This enables us to eliminate all zero rows in the submatrix \(A( ., \mathcal{J}) .\) We denote the resulting submatrix \(A(\mathcal{I}, \mathcal{J})\) by by
	\(\hat{A}\) . Similarly, we define \(\hat{e}_{k}=e_{k}(\mathcal{I}) .\) If we now set \(n_{1}=|\mathcal{I}|\) and \(n_{2}=|\mathcal{J}|,\) we see that
	solving \((4)\) for \(m_{k}\) is equivalent to solving
	
	\begin{equation}
	\min _{\hat{m}_{k}}\left\|\hat{A} \hat{m}_{k}-\hat{e}_{k}\right\|_{2}
	\end{equation}
	
	
	
	\begin{equation}
	\hat{A}=Q\left(\begin{array}{l}{R} \\ {0}\end{array}\right)
	\end{equation}
	
	where \(R\) is a nonsingular upper triangular \(n_{2} \times n_{2}\) matrix. If we let \(\hat{c}=Q^{T} \hat{e}_{k},\) the
	solution of  is
	
	\begin{equation}
	\hat{m}_{k}=R^{-1} \hat{c}\left(1 : n_{2}\right)
	\end{equation}
	
	Solve (5) for every column of M to get an approximate inverse. The next 
	step is to increase the sparsity structure to improve upon the previous solution.
	
	The idea is to add indices that will lead to best reduction in error. We recall that the current error is \(\|A M-I\|_{F},\), in other words to \(\left\|A m_{k}-e_{k}\right\|_{2}\) for each \(k=1, \ldots, n .\) We recall that \(m_{k}\) is the optimal solution of the least squares problem (4), and we denote its residual by
	
	\begin{equation}
	r=A( ., \mathcal{J}) \hat{m}_{k}-e_{k}
	\end{equation}
	
	must be included in \(\mathcal{L}\) since \(r(k)\) is then equal to \(-1 .\) To every \(\ell \in \mathcal{L}\) corresponds an
	index set \(\mathcal{N}_{\ell},\) which consists of the indices of the nonzero elements of \(A(\ell, .)\) that are
	
	
	\begin{equation}
	\tilde{\mathcal{J}}=\bigcup_{\ell \in \mathcal{L}} \mathcal{N}_{\ell}
	\end{equation}
	
	\begin{equation}
	\tilde{\mathcal{J}}=\bigcup_{\ell \in \mathcal{L}} \mathcal{N}_{\ell}
	\end{equation}
	
	\begin{equation}
	\min _{\mu_{j}}\left\|r+\mu_{j} A e_{j}\right\|_{2}
	\end{equation}
	
	\begin{equation}
	\mu_{j}=-\frac{r^{T} A e_{j}}{\left\|A e_{j}\right\|_{2}^{2}}
	\end{equation}
	
	\begin{equation}
	\rho_{j}^{2}=\|r\|_{2}^{2}-\frac{\left(r^{T} A e_{j}\right)^{2}}{\left\|A e_{j}\right\|_{2}^{2}}
	\end{equation}
	
	\begin{equation}
	0=r(\mathcal{L})^{T} A(\mathcal{L}, \tilde{\mathcal{J}})=r(\mathcal{L})^{T} A(\mathcal{L}, \mathcal{J} \cup \tilde{\mathcal{J}})
	\end{equation}
	
	\newpage

\section{Theorem 3.3}

The statement of this theorem is as follows: 
%We now derive bounds for the singular values and the condition number of AM.
\begin{theorem}
The singular values of \(A M\) are clustered at 1 and lie inside the
interval \([1-\delta, 1+\delta],\) with \(\delta=\sqrt{n} \varepsilon(2+\sqrt{n} \varepsilon) .\) Furthermore, if \(\delta<1,\) then the
condition number of \(A M\) satisfies

\begin{equation}
\operatorname{cond}_{2}(A M) \leq \sqrt{\frac{1+\delta}{1-\delta}}
\end{equation}


\end{theorem}

\paragraph{Remark.} We believe that there is a minor typo in the statement of the original theorem as singular values lie inside the interval  \([\sqrt{1-\delta}, \sqrt{1+\delta}],\), which is evident from the nature of the bound on the condition number. 


\begin{lemma}
Let \(p=\max _{1 \leq k \leq n}\left\{\text { number of nonzero elements of } r_{k}\right\} .\) Then
\begin{equation}
\|A M-I\|_{F} \leq \sqrt{n} \varepsilon \label{lem1a}
\end{equation}

\begin{equation}
\|A M-I\|_{2} \leq \sqrt{n} \varepsilon \label{lem1b}
\end{equation}

\begin{equation}
\|A M-I\|_{1} \leq \sqrt{p} \varepsilon \label{lem1c}
\end{equation}
\end{lemma}

\begin{proof}

\begin{equation}
\|A M-I\|_{F}^{2}=\sum_{k=1}^{n}\left\|(A M-I) e_{k}\right\|_{2}^{2} \leq \sum_{k=1}^{n} \varepsilon^{2}=n \varepsilon^{2}
\end{equation}

\begin{align}
\|A M-I\|_{2} &=\max _{\|x\|_{2}=1}\|(A M-I) x\|_{2} =\max _{\|x\|_{2}=1}\left\|\sum_{k=1}^{n} x_{k}(A M-I) e_{k}\right\|_{2} \\
&\leq \max _{\|x\|_{2}=1}\|x\|_{1} \varepsilon \leq \sqrt{n} \varepsilon
\end{align}

\begin{align}
\|A M-I\|_{1} &\overset{\text{def}}{=}\max_{1 \leq k \leq n}\left\|A m_k - e_k\right\|_{1} \label{l1matrix} \\
&\leq \sqrt{p} \max_{1 \leq k \leq n}\left\|A m_k - e_k\right\|_{2} 
\end{align}


\end{proof}

\begin{lemma}
	
Gershgorin's Theorem
%Let A be an n x n matrix 
\begin{equation}\label{gers1}
D_{i}=\left\{z \in \mathbb{C} \, | \, | z-a_{i i} | \leq R_{i}\right\}, \text{where} \; R_{i}=\sum_{j \neq i}\, \left|a_{i j}\right|
\end{equation}

Corollary: The eigenvalues of A must also lie within the Gershgorin discs $C_j$ corresponding to the columns of A. \\


\end{lemma}

\begin{lemma}
The eigenvalues $\lambda_k$ of $AM$ are clustered at 1 and lie inside a circle of radius $\sqrt{p} \varepsilon$
\end{lemma}

\begin{proof}
	
Let $Q R Q^{T}$ be a Schur decomposition of $A M-I$. Then:

\begin{equation}
\sum_{k=1}^{n}\left|1-\lambda_{k}\right|^{2}=\|\operatorname{diag}(R)\|_{2}^{2} \leq\|R\|_{F}^{2}=\|A M-I\|_{F}^{2} \leq n \varepsilon^{2}
\end{equation}

\begin{equation}
\frac{1}{n} \sum_{k=1}^{n}\left|1-\lambda_{k}\right|^{2} \leq \varepsilon^{2}
\end{equation}
This implies that the eigenvalues are clustered around 1. The part about them lying inside a circle is shown ahead. Let's denote the matrix $A M$ by $G$ and $A M - I$ by $\tilde{G}$. The individual entries of these matrices are denoted by the respective lowercase letters. Then, we can write

\begin{equation}\label{gers2}
\left|\lambda_{k} - 1 \right| = \left|\lambda_{k} - \dk  + \dk - 1 \right| \leq \left|\lambda_{k} - \dk \right|  + \left|\dk - 1 \right| %\eq = \left|\lambda_{k} - \dk \right|  + \left|\tilde{g}_{kk}\right|
\end{equation}

Applying corollary of Lemma 2, i.e. in particular using the Gershgorin's disc $C_k$ corresponding to column $k$, we obtain:

\begin{equation}\label{gers3}
\left|\lambda_{k} - \dk \right| \leq \sum_{j \neq k}\, \left|g_{j k}\right|
\end{equation}

Since $ \dktil = \dk - 1 $ and $\tilde{g}_{j k} = g_{j k}$ (for $j\neq k$), from equations \eqref{gers2} and \eqref{gers3}, we have:  

\begin{equation}\label{gers4}
\left|\lambda_{k} - 1 \right| \leq \sum_{j \neq k}\, \left|\tilde{g}_{j k}\right| + \left|\dktil\right| = \sum_{j }\, \left|\tilde{g}_{j k}\right| = \|A m_k -e_k\|_{1} \overset{\eqref{l1matrix}}{\leq} \|A M-I\|_{1}
\end{equation}

Thus from the above equation \eqref{gers4} and equation \eqref{lem1c} in lemma 1, we conclude that eigenvalues of the matrix $A M$ satisfy $ \left|\lambda_{k} - 1 \right| \leq \sqrt{p} \varepsilon$ and hence lie inside the required circle.
\end{proof}


%$$
%\square
%$$
\vspace{2em}
\begin{proof}[\textbf{Proof of the main theorem.}] 

Now, with these lemma's in place let's get back to proving the original theorem. \\

Since the singular values of $AM$ are the square roots of the eigenvalues of $A M M^{T} A^{T} $, 

\begin{equation}
\left\|I-A M M^{T} A^{T}\right\|_{2}=\left\|I+(I-A M) M^{T} A^{T}-M^{T} A^{T}\right\|_{2}
\end{equation}

\begin{equation}
\sqrt{n} \varepsilon\left(1+\|A M\|_{2}\right) \leq \sqrt{n} \varepsilon\left(1+\|A M-I+I\|_{2}\right) \leq \sqrt{n} \varepsilon(2+\sqrt{n} \varepsilon)
\end{equation}

\begin{equation}
\operatorname{cond}_{2}(A M) \leq \sqrt{\frac{1+\delta}{1-\delta}}
\end{equation}

Finally, applying Lemma 3 to the matrix $ A M M^{T} A^{T} $ instead of $ A M$ we conclude that the singular values are indeed clustered at 1 and lie inside the interval \([\sqrt{1-\delta}, \sqrt{1+\delta}]\).
\end{proof}


%TODO
% Make it lemma 1.1 and 1.2 and so on! 
\end{document}